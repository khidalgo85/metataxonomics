
<!-- README.md is generated from README.Rmd. Please edit that file -->
<!-- badges: start -->

![forthebadge](https://img.shields.io/badge/GEMM-Building-orange)
![forthebadge](https://forthebadge.com/images/badges/built-with-science.svg)
<!-- badges: end -->

# Metataxon√¥mica usando o sequenciamento masivo do gene 16S rRNA<img src="imgs/1.png" align="right" width = "120px"/>

**Autor: Kelly Hidalgo**

Em este tutorial voc√™ aprender√° como processar sequencias do gene 16S
rRNA com duas abordagens: **1)** DADA2 usando a linguagem de programa√ß√£o
R no IDLE RStudio e **2)** Qiime2.

## Introdu√ß√£o

Ambos pipelines s√£o capazes de analizar sequencias do gene 16S rRNA
usando ASVs (*Amplicon Sequence Vatiants*) ao inv√©s de OTUs
(*Operational Taxonomic Units*).

A continua√ß√£o, vamos a comparar ambas abordagens:

**Qiime2**

-   *User-friendly*
-   Interfaz gr√°fica
-   Muita documenta√ß√£o [qiime2.org](https://docs.qiime2.org/2021.4/)
-   Gera√ß√£o r√°pida de gr√°ficos
-   Requiere pouco conhecimento em bioinform√°tica e/ou linguagens de
    programa√ß√£o

**DADA2**

-   Mais **acurado**
-   Melhor *performance*
-   Requiere conhecimento na linguaguem de programa√ß√£o R

### OTU vs ASV

Agora, vamos a revisar muito superficialmente que √© OTU e ASV.

**OTU *(Operational Taxonomic Unit)*:** √â a m√≠mina unidade taxon√¥mica
usada para classificar grupos de individuos relacionados. Tipicamente,
com esta defini√ß√£o, las sequencias s√£o agrupadas baseado na porcentagem
de similaridade entre ellas (usualmente 97% de similaridade). Se ainda
n√£o conseguiu entender, tente pensar que cada OTU √© como uma caixa, que
pode ter nome (esp√©cies conhecidas) ou n√£o (esp√©cies desconhecidas) e
dentro de cada caixa todos os individuos s√£o similares entre eles em no
m√≠nimo um 97%. **ASV (*Amplicon Sequence Vatiant*):** √â o termo usado
para se referir a sequencias de DNA individuais. Agora j√° n√£o √© mais
poss√≠vel pensar que s√£o caixas, porque os ASVs n√£o s√£o agrupados por
similaridade. Este conceito considera que cada sequencia √© diferente de
outra desde a varia√ß√£o de uma base nucleot√≠dica.

**Mas por que existem dois conceitos diferentes?** Bom, porque os
investigadores tem observado que duas esp√©cies nem sempre s√£o diferentes
porque as sequencias sejam 3% dissimilares. H√° casos onde sequencias com
menos de 3% de dissimilaridad s√£o a mesma esp√©cie. E outro casos onde
esp√©cies com 97% de similaridade na realidade n√£o s√£o a mesma esp√©cie.

A seguinte figura mostra a diferen√ßa entre os dois tipos de
clusteriza√ß√£o. <img src="imgs/otus_vs_asvs.png" align="center"/>

Esta figura √© modificada da figura S1 de [*Callahan et
al.¬†2016*](https://www.nature.com/articles/nmeth.3869)

A figura mostra um vis√£o global do processo de metabarcoding, com os
potenciais vi√©ses que podem afetar a ac√∫racia do sequenciamento. Na
se√ß√£o **(A)** na amostra h√° v√°rias esp√©cies com diferente quantidade de
biomasa (indicado pelo tamanho das bolinhas) e distintos hapl√≥tipos
(indicado pela cor). Depois da extra√ß√£o de DNA, o *barcode* √©
amplificado usando PCR **(B)**, o qual vai distorcer as abund√¢ncias das
sequ√™ncias, e tamb√©m pode n√£o amplificar taxas devido ao vi√©s nos
primers ou profundidade insuficiente do sequenciamento no caso de
esp√©cies subrepresentadas/raras (*rosa - sp.5*). No processo de
sequenciamento *high-throughput* **(C)**, muitas novas sequ√™ncias de
falsos positivos s√£o geradas devido aos erros de sequenciamento,
forma√ß√£o de quimeras e mistura de amostras multiplexadas. O impacto de
estes erros frequentemente pode ser reduzido em um processo de filtragem
riguroso e agrupando sequ√™ncias similares em OTUs. Normalmente, s√≥ a
sequ√™ncia mais abundante em uma OTU √© considerada e usada para
identificar a respectiva esp√©cie (centroide), o que por sua vez
significa que as informa√ß√µes sobre diversidade s√£o perdidas. **(D)** as
estrategias de ***denoising*** s√£o usadas para remover do dataset
sequ√™ncias com afetadas por erros are used to remove error-affected
sequences from a dataset e reativar as sequ√™ncias de hapl√≥tipos reais
presentas em uma amostras. O Denoising (remo√ß√£o do ru√≠do) pode
discriminar entre um erro do sequenciamento ou da amplifica√ß√£o com PCR e
uma esp√©cie diferente (diferen√ßa de pelo menos um nucleot√≠deo). A base √©
que se a sequ√™ncia estiver super-representada (abundante), √© mais
prov√°vel que seja uma determinada sequ√™ncia, mas se a sequ√™ncia estiver
em baixa abund√¢ncia √© prov√°vel que seja devido a um erro na PCR ou no
sequenciamento. Em resumo, usando o conceito de OTU, neste exemplo
conderar√≠amos apenas 3 OTUs ou esp√©cies diferentes, enquanto que usando
a abordagem de denoising √© poss√≠vel obter 5 ASVs ou esp√©cies diferentes.

------------------------------------------------------------------------

# I Metataxonomica com Qiime2

## 0. Instala√ß√µes

### 0.1. Intala√ß√£o Anaconda

√â recomend√°vel instalar Anaconda, pois √© a forma mais f√°cil para
instalar as ferramentas bioinform√°ticas necess√°rias pro desenvolvimento
deste pipeline. Anaconda √© uma distribui√ß√£o livre e aberta das
linguagens *Python* e *R*, utilizada na ci√™ncia de dados e
bioinform√°tica. As diferente vers√µes dos programas se administram
mediante um sinstema de gest√£o chamado *conda*, o qual faz bastante
simples instalar, rodar e atualizar programas.
[Aqui](https://conda.io/projects/conda/en/latest/user-guide/install/index.html)
se encontram as instru√ß√µes para a instala√ß√£o de Anaconda.

Depois de instalado, *Anaconda* e o gestor *Conda*, podram ser criados
*ambientes virtuais* par a instala√ß√£o das diferentes ferramentas
bioinform√°tica que ser√£o usadas.

### 0.2. Instala√ß√£o Qiime2-2021.4

Uma vez instalado Anaconda, use as seguintes
[instru√ß√µes](https://docs.qiime2.org/2021.4/install/native/#install-qiime-2-within-a-conda-environment)
para instalar facilmente **Qiime2-2021.4**.

### 0.3. Instala√ß√£o RESCRIPt

RESCRIPt (*REference Sequence annotation and CuRatIon Pipeline*) √© uma
ferramenta escrita em python3 para gestionar e curar as bases de dados,
sequencias de DNA/RNA e a informa√ß√£o taxon√¥mica. [Reposit√≥rio
GitHub](https://github.com/bokulich-lab/RESCRIPt).

Para instalar este plugin dentro do Qiime2, siga as seguintes
instru√ß√µes:

    ## Ative o ambiente qiime2-2021.4
    conda activate qiime2-2021.4
    ## Instale as dependencias
    conda install -c conda-forge -c bioconda -c qiime2 -c defaults xmltodict
    ## InstaLe desde a fonte
    pip install git+https://github.com/bokulich-lab/RESCRIPt.git

## 1. Organizando os dados

### 1.1. Amostras

Para este tutorial ser√° usado um *dataset* de sequenciamento do gene 16S
rRNA com Illumina (*paired-end*) de 28 amostras de lodos de duas plantas
de tratamento de esgoto, uma numa escola p√∫blica localizada no municipio
de Pinhal e outra de uma f√°brica de fibra de vidro da cidade de
Iracem√°polis. Pra mais detalhes, consulte o
[paper](https://link.springer.com/article/10.1007/s10532-020-09921-y)
publicado sobre o estudo.

Para descarregar os dados:

    ## Crie um diret√≥rio base
    mkdir metataxonomics

    cd metataxonomics/
    ## Crie um diret√≥rio para os dados
    mkdir 00.RawData

    cd 00.RawData/

    ## Descarregue o arquivo .zip
    wget https://figshare.com/ndownloader/files/31594295

    ## Fa√ßa unzip no arquivo
    unzip 31594295

    ## Clean the directory
    rm 31594295

Agora, com `ls` liste os arquivos dentro de `00.RawData`, se deve ver
assim:

    sample1_1.fq.gz   sample1_2.fq.gz   sample2_1.fq.gz   sample2_2.fq.gz   sample3_1.fq.gz   sample3_2.fq.gz   sample4_1.fq.gz   sample4_2.fq.gz   sample5_1.fq.gz   sample5_2.fq.gz   sample6_1.fq.gz   sample6_2.fq.gz   sample7_1.fq.gz   sample7_2.fq.gz   sample8_1.fq.gz   sample8_2.fq.gz   sample9_1.fq.gz   sample9_2.fq.gz   sample10_1.fq.gz   sample10_2.fq.gz   sample11_1.fq.gz   sample11_2.fq.gz   sample12_1.fq.gz   sample12_2.fq.gz   sample13_1.fq.gz   sample13_2.fq.gz   sample14_1.fq.gz   sample14_2.fq.gz   sample15_1.fq.gz   sample15_2.fq.gz   sample16_1.fq.gz   sample16_2.fq.gz   sample17_1.fq.gz   sample17_2.fq.gz   sample18_1.fq.gz   sample18_2.fq.gz   sample19_1.fq.gz   sample19_2.fq.gz   sample20_1.fq.gz   sample20_2.fq.gz   sample21_1.fq.gz   sample21_2.fq.gz   sample22_1.fq.gz   sample22_2.fq.gz   sample23_1.fq.gz   sample23_2.fq.gz   sample24_1.fq.gz   sample24_2.fq.gz   sample25_1.fq.gz   sample25_2.fq.gz   sample26_1.fq.gz   sample26_2.fq.gz   sample27_1.fq.gz   sample27_2.fq.gz   sample28_1.fq.gz   sample28_2.fq.gz

√â muito recomendado rodar todos los comando desde o diret√≥rio base
`metataxonomics/`

    cd ..
    # Onde estou?
    pwd

Se estiver correto, voc√™ estar√° dentro da pasta `~/metataxonomics`

## 2. Importar as sequ√™ncias como artefato `.qza`

Um dos arquivos especiais do Qiime2 s√£o os artefatos, os quais s√£o
considerados para representar os dados intermediarios na an√°lise. Assim,
os artefatos s√£o considerados arquivos gerado por Qiime2 e s√≥ podem ser
usados em Qiime2. A extens√£o √© `.qza` que significa *Qiime Zipped
Artifact*, para mais informa√ß√£o, Qiiem2 tem um
[gloss√°rio](https://docs.qiime2.org/2021.4/glossary/).

Neste passo as sequ√™ncias ser√£o importadas como arquivo `.qza`. Antes
disso, √© necess√°rio criar um arquivo chamado `ManifestFile.csv`, onde
devem ser indicados os caminhos e nomes das amostras, com o intuito de
que o Qiime2 seja capaz de importar as *reads*. H√° outras maneiras de
importar as *reads* que dependen do tipo de sequ√™ncias a serem
importadas. [Aqui](https://docs.qiime2.org/2021.4/tutorials/importing/),
encontra informa√ß√µes sobre isto.

Para criar o `ManifestFile.csv`, pode usar excel ou diretamente no bash,
seguindo as instru√ß√µes a continua√ß√£o:

Abra o editor de texto `nano`

    nano ManifestFile.csv

Fa√ßa uma tabela de tr√™s colunas separadas com v√≠rgulas `,`. A primeira
coluna deve ser `sample-id`, aqui voc√™ indica o nome da amostra
personalizada, a segunda coluna √© `absolute-filepath` para colocar o
caminho para cada pair, e a √∫ltima coluna √© `direction`, para indicar se
se trata do pair *forward* ou *reverse*.

Tanto na f√°brica de fibra de vidro (**I**racem√°polis) como na escola
(**P**inhal) foram amostrados lodos no tanque septico (ST), e no filtro
anaer√≥bico (AF) nas quatro esta√ß√µes do ano, durante 2018 e 2019. Ent√£o
por exemplo a amostra 4 (Sample4), com sample-id STI1-Jan19, √© uma
amostra de lodo tomado no tanque septico (ST) da f√°brica de vidro (I) em
Janeiro do 2019 (Jan19) e √© a replicata 1 (todas as amostras foram
tomadas em duplicata).

Se sua maquina tem uma boa capacidade (m√≠nimo processador com 8 n√∫cleos
e 16 Gb de RAM) processe todas as amostras usando o seguinte
ManifestFile. Se pelo contr√°rio quer testar no seu laptop (m√≠nimo
processador com 4 n√∫cleos, 8 Gb de RAM), use o segundo ManifestFile que
cont√©m menos amostras.

Aqui o exemplo (todas as 28 amostras):

    sample-id,absolute-filepath,direction
    STI2-Apr19,$PWD/00.RawData/sample1_1.fq.gz,forward
    STI2-Apr19,$PWD/00.RawData/sample1_2.fq.gz,reverse
    STI1-Apr19,$PWD/00.RawData/sample2_1.fq.gz,forward
    STI1-Apr19,$PWD/00.RawData/sample2_2.fq.gz,reverse
    AFI2-Jan19,$PWD/00.RawData/sample3_1.fq.gz,forward
    AFI2-Jan19,$PWD/00.RawData/sample3_2.fq.gz,reverse
    STI1-Jan19,$PWD/00.RawData/sample4_1.fq.gz,forward
    STI1-Jan19,$PWD/00.RawData/sample4_2.fq.gz,reverse
    STI2-Oct18,$PWD/00.RawData/sample5_1.fq.gz,forward
    STI2-Oct18,$PWD/00.RawData/sample5_2.fq.gz,reverse
    STI1-Oct18,$PWD/00.RawData/sample6_1.fq.gz,forward
    STI1-Oct18,$PWD/00.RawData/sample6_2.fq.gz,reverse
    AFI1-Jan19,$PWD/00.RawData/sample7_1.fq.gz,forward
    AFI1-Jan19,$PWD/00.RawData/sample7_2.fq.gz,reverse
    STI2-Jan19,$PWD/00.RawData/sample8_1.fq.gz,forward
    STI2-Jan19,$PWD/00.RawData/sample8_2.fq.gz,reverse
    AFI2-Apr19,$PWD/00.RawData/sample9_1.fq.gz,forward
    AFI2-Apr19,$PWD/00.RawData/sample9_2.fq.gz,reverse
    AFI1-Apr19,$PWD/00.RawData/sample10_1.fq.gz,forward
    AFI1-Apr19,$PWD/00.RawData/sample10_2.fq.gz,reverse
    AFI2-Oct18,$PWD/00.RawData/sample11_1.fq.gz,forward
    AFI2-Oct18,$PWD/00.RawData/sample11_2.fq.gz,reverse
    AFI1-Oct18,$PWD/00.RawData/sample12_1.fq.gz,forward
    AFI1-Oct18,$PWD/00.RawData/sample12_2.fq.gz,reverse
    AFP2-Aug18,$PWD/00.RawData/sample13_1.fq.gz,forward
    AFP2-Aug18,$PWD/00.RawData/sample13_2.fq.gz,reverse
    AFP1-Aug18,$PWD/00.RawData/sample14_1.fq.gz,forward
    AFP1-Aug18,$PWD/00.RawData/sample14_2.fq.gz,reverse
    STP1-Aug18,$PWD/00.RawData/sample15_1.fq.gz,forward
    STP1-Aug18,$PWD/00.RawData/sample15_2.fq.gz,reverse
    STP2-Aug18,$PWD/00.RawData/sample16_1.fq.gz,forward
    STP2-Aug18,$PWD/00.RawData/sample16_2.fq.gz,reverse
    STI1-Sep18,$PWD/00.RawData/sample17_1.fq.gz,forward
    STI1-Sep18,$PWD/00.RawData/sample17_2.fq.gz,reverse
    STI2-Sep18,$PWD/00.RawData/sample18_1.fq.gz,forward
    STI2-Sep18,$PWD/00.RawData/sample18_2.fq.gz,reverse
    STP1-Jun18,$PWD/00.RawData/sample19_1.fq.gz,forward
    STP1-Jun18,$PWD/00.RawData/sample19_2.fq.gz,reverse
    STP2-Jun18,$PWD/00.RawData/sample20_1.fq.gz,forward
    STP2-Jun18,$PWD/00.RawData/sample20_2.fq.gz,reverse
    STP1-Jun19,$PWD/00.RawData/sample21_1.fq.gz,forward
    STP1-Jun19,$PWD/00.RawData/sample21_2.fq.gz,reverse
    STP2-Jun19,$PWD/00.RawData/sample22_1.fq.gz,forward
    STP2-Jun19,$PWD/00.RawData/sample22_2.fq.gz,reverse
    AFI1-Sep18,$PWD/00.RawData/sample23_1.fq.gz,forward
    AFI1-Sep18,$PWD/00.RawData/sample23_2.fq.gz,reverse
    AFI2-Sep18,$PWD/00.RawData/sample24_1.fq.gz,forward
    AFI2-Sep18,$PWD/00.RawData/sample24_2.fq.gz,reverse
    AFP1-Jun18,$PWD/00.RawData/sample25_1.fq.gz,forward
    AFP1-Jun18,$PWD/00.RawData/sample25_2.fq.gz,reverse
    AFP2-Jun18,$PWD/00.RawData/sample26_1.fq.gz,forward
    AFP2-Jun18,$PWD/00.RawData/sample26_2.fq.gz,reverse
    STP2-Oct18,$PWD/00.RawData/sample27_1.fq.gz,forward
    STP2-Oct18,$PWD/00.RawData/sample27_2.fq.gz,reverse
    STP1-Oct18,$PWD/00.RawData/sample28_1.fq.gz,forward
    STP1-Oct18,$PWD/00.RawData/sample28_2.fq.gz,reverse

Com ctrl+x voc√™ pode sair do nano, o sistema vai perguntar se quer
salvar as mudan√ßas, d√≠gite `yes`.

Aqui o exemplo (16 Amostras da f√°brica de fibra de vidrio):

    sample-id,absolute-filepath,direction
    STI2-Apr19,$PWD/00.RawData/sample1_1.fq.gz,forward
    STI2-Apr19,$PWD/00.RawData/sample1_2.fq.gz,reverse
    STI1-Apr19,$PWD/00.RawData/sample2_1.fq.gz,forward
    STI1-Apr19,$PWD/00.RawData/sample2_2.fq.gz,reverse
    AFI2-Jan19,$PWD/00.RawData/sample3_1.fq.gz,forward
    AFI2-Jan19,$PWD/00.RawData/sample3_2.fq.gz,reverse
    STI1-Jan19,$PWD/00.RawData/sample4_1.fq.gz,forward
    STI1-Jan19,$PWD/00.RawData/sample4_2.fq.gz,reverse
    STI2-Oct18,$PWD/00.RawData/sample5_1.fq.gz,forward
    STI2-Oct18,$PWD/00.RawData/sample5_2.fq.gz,reverse
    STI1-Oct18,$PWD/00.RawData/sample6_1.fq.gz,forward
    STI1-Oct18,$PWD/00.RawData/sample6_2.fq.gz,reverse
    AFI1-Jan19,$PWD/00.RawData/sample7_1.fq.gz,forward
    AFI1-Jan19,$PWD/00.RawData/sample7_2.fq.gz,reverse
    STI2-Jan19,$PWD/00.RawData/sample8_1.fq.gz,forward
    STI2-Jan19,$PWD/00.RawData/sample8_2.fq.gz,reverse
    AFI2-Apr19,$PWD/00.RawData/sample9_1.fq.gz,forward
    AFI2-Apr19,$PWD/00.RawData/sample9_2.fq.gz,reverse
    AFI1-Apr19,$PWD/00.RawData/sample10_1.fq.gz,forward
    AFI1-Apr19,$PWD/00.RawData/sample10_2.fq.gz,reverse
    AFI2-Oct18,$PWD/00.RawData/sample11_1.fq.gz,forward
    AFI2-Oct18,$PWD/00.RawData/sample11_2.fq.gz,reverse
    AFI1-Oct18,$PWD/00.RawData/sample12_1.fq.gz,forward
    AFI1-Oct18,$PWD/00.RawData/sample12_2.fq.gz,reverse
    STI1-Sep18,$PWD/00.RawData/sample17_1.fq.gz,forward
    STI1-Sep18,$PWD/00.RawData/sample17_2.fq.gz,reverse
    STI2-Sep18,$PWD/00.RawData/sample18_1.fq.gz,forward
    STI2-Sep18,$PWD/00.RawData/sample18_2.fq.gz,reverse
    AFI1-Sep18,$PWD/00.RawData/sample23_1.fq.gz,forward
    AFI1-Sep18,$PWD/00.RawData/sample23_2.fq.gz,reverse
    AFI2-Sep18,$PWD/00.RawData/sample24_1.fq.gz,forward
    AFI2-Sep18,$PWD/00.RawData/sample24_2.fq.gz,reverse

Se quiser selecionar apenas as 12 amostras da escola, use este
ManifestFile

    sample-id,absolute-filepath,direction
    AFP2-Aug18,$PWD/00.RawData/sample13_1.fq.gz,forward
    AFP2-Aug18,$PWD/00.RawData/sample13_2.fq.gz,reverse
    AFP1-Aug18,$PWD/00.RawData/sample14_1.fq.gz,forward
    AFP1-Aug18,$PWD/00.RawData/sample14_2.fq.gz,reverse
    STP1-Aug18,$PWD/00.RawData/sample15_1.fq.gz,forward
    STP1-Aug18,$PWD/00.RawData/sample15_2.fq.gz,reverse
    STP2-Aug18,$PWD/00.RawData/sample16_1.fq.gz,forward
    STP2-Aug18,$PWD/00.RawData/sample16_2.fq.gz,reverse
    STP1-Jun18,$PWD/00.RawData/sample19_1.fq.gz,forward
    STP1-Jun18,$PWD/00.RawData/sample19_2.fq.gz,reverse
    STP2-Jun18,$PWD/00.RawData/sample20_1.fq.gz,forward
    STP2-Jun18,$PWD/00.RawData/sample20_2.fq.gz,reverse
    STP1-Jun19,$PWD/00.RawData/sample21_1.fq.gz,forward
    STP1-Jun19,$PWD/00.RawData/sample21_2.fq.gz,reverse
    STP2-Jun19,$PWD/00.RawData/sample22_1.fq.gz,forward
    STP2-Jun19,$PWD/00.RawData/sample22_2.fq.gz,reverse
    AFP1-Jun18,$PWD/00.RawData/sample25_1.fq.gz,forward
    AFP1-Jun18,$PWD/00.RawData/sample25_2.fq.gz,reverse
    AFP2-Jun18,$PWD/00.RawData/sample26_1.fq.gz,forward
    AFP2-Jun18,$PWD/00.RawData/sample26_2.fq.gz,reverse
    STP2-Oct18,$PWD/00.RawData/sample27_1.fq.gz,forward
    STP2-Oct18,$PWD/00.RawData/sample27_2.fq.gz,reverse
    STP1-Oct18,$PWD/00.RawData/sample28_1.fq.gz,forward
    STP1-Oct18,$PWD/00.RawData/sample28_2.fq.gz,reverse

Ou tamb√©m poderia s√≥ pegar uma replicata de cada amostra (14):

    sample-id,absolute-filepath,direction
    =-09876545678976457805433470987651<wertyuikjxz 
    AFP1-Aug18,$PWD/00.RawData/sample14_1.fq.gz,forward
    AFP1-Aug18,$PWD/00.RawData/sample14_2.fq.gz,reverse
    STP1-Aug18,$PWD/00.RawData/sample15_1.fq.gz,forward
    STP1-Aug18,$PWD/00.RawData/sample15_2.fq.gz,reverse
    STI1-Sep18,$PWD/00.RawData/sample17_1.fq.gz,forward
    STI1-Sep18,$PWD/00.RawData/sample17_2.fq.gz,reverse
    STP1-Jun18,$PWD/00.RawData/sample19_1.fq.gz,forward
    STP1-Jun18,$PWD/00.RawData/sample19_2.fq.gz,reverse
    STP1-Jun19,$PWD/00.RawData/sample21_1.fq.gz,forward
    STP1-Jun19,$PWD/00.RawData/sample21_2.fq.gz,reverse
    AFI1-Sep18,$PWD/00.RawData/sample23_1.fq.gz,forward
    AFI1-Sep18,$PWD/00.RawData/sample23_2.fq.gz,reverse
    AFP1-Jun18,$PWD/00.RawData/sample25_1.fq.gz,forward
    AFP1-Jun18,$PWD/00.RawData/sample25_2.fq.gz,reverse
    STP1-Oct18,$PWD/00.RawData/sample28_1.fq.gz,forward
    STP1-Oct18,$PWD/00.RawData/sample28_2.fq.gz,reverse

O tutorial ser√° feito com as 12 amostras da escola. Importe as
sequ√™ncias com o seguinte comando:

    # Activate qiime2 environment
    conda activate qiime2-2021.4
    # Create a new directory
    mkdir 01.ReadsQza
    # Import
    qiime tools import \
      --type 'SampleData[PairedEndSequencesWithQuality]' \
      --input-path ManifestFile.csv \
      --output-path 01.ReadsQza/rawreads.qza \
      --input-format PairedEndFastqManifestPhred33

Agora todas as amostras e seus pares est√£o dentro de um arquivo s√≥
chamado `rawreads.qza`. Se voc√™ quiser visualizar este arquivo, voc√™
deve transformar a `.qzv` (*Qiime zipped visualization*), e voc√™ pode
visualizarlo em [view.qiime2.org](Qiime2%20View).

    qiime demux summarize \
     --i-data 01.ReadsQza/rawreads.qza \
     --o-visualization 01.ReadsQza/rawreads.qzv

No arquivo de visualiza√ß√£o voc√™ pode obter algumas estat√≠sticas b√°sicas,
como o m√≠nimo, m√°ximo, memdiana √© m√©dia do n√∫mero de sequ√™ncias em todo
o dataset. Tamb√©m pode ver um histograma das frequ√™ncias das sequ√™ncias
forward e reverse. O relat√≥rio, al√©m tem uma tabela com o conteo de
sequ√™ncias por amostra. No gr√°fico interativo de qualidade, voc√™ pode
avaliar a qualidade, pelo valor do *Phred score*.

## 3. Remo√ß√£o de Primers

**Cutadapt** √© um plugin do Qiime2 usado para trimar os primers das
sequ√™ncias. O presente *dataset* de exemplo foi sequ√™nciada a regi√£o V4
usando os primers 515F-806R.

    --p-front-f GTGYCAGCMGCCGCGGTAA \
    --p-front-r GGACTACNVGGGTWTCTAAT \

Com o seguinte comando, v√£o ser removidos os primers:

    qiime cutadapt trim-paired \
       --i-demultiplexed-sequences 01.ReadsQza/rawreads.qza \
       --p-cores 10 \
       --p-front-f GTGYCAGCMGCCGCGGTAA \
       --p-front-r GGACTACNVGGGTWTCTAAT \
       --p-discard-untrimmed \
       --p-no-indels \
       --o-trimmed-sequences 01.ReadsQza/trimmedreads.qza

Os primers para a regi√µes V3/V4 do gene 16S rRNA (bact√©roas) s√£o:

    --p-front-f CCTAYGGGRBGCASCAG \
    -p-front-r GGACTACNNGGGTATCTAAT \

Os primers para as regi√µes V4/V5 do gene 16S rRNA (bact√©rias) s√£o:

    --p-front-f GTGYCAGCMGCCGCGGTAA \
    --p-front-r CCGYCAATTYMTTTRAGTTT \

Para as regi√µes V6/V8 do gene 16S rRNA (Archaeas) s√£o:

    --p-front-f TYAATYGGANTCAACRCC \
    --p-front-r CRGTGWGTRCAAGGRGCA \

Para as regi√µes V6/V8 do gene 16S rRNA (Bact√©rias) s√£o:

    --p-front-f ACGCGHNRAACCTTACC \
    --p-front-r ACGGGCRGTGWGTRCAA \

Para a regi√£o V4 do gene 18S rRNA s√£o:

    --p-front-f CYGCGGTAATTCCAGCTC \
    --p-front-r AYGGTATCTRATCRTCTTYG \

Para a regi√£o ITS2 em fungos s√£o:

    --p-front-f GTGAATCATCGAATCTTTGAA \
    --p-front-r TCCTCCGCTTATTGATATGC \

Ok, agora voc√™ tem suas sequ√™ncias sem primers. Rode novamente o comando
`demux summarize` para determinar o n√∫mero de sequ√™ncias depois da
trimagem dos primers:

    qiime demux summarize \
       --i-data 01.ReadsQza/trimmedreads.qza\
       --o-visualization 01.ReadsQza/trimmedreads.qzv

Compare o n√∫mero de sequ√™ncias antes e depois da trimagem dos primers.
Se voc√™ perdeu uma porcentagem muito alto, revise a sequ√™ncias dos
primers usados para seu sequ√™nciamento.

## 4. Denoising em ASVs

Qiime2 oferece dois diferentes *pipelines* para este paso, **deblur** e
**DADA2**. Aqui usaremos **DADA2**.

Em esta etapa, **DADA2** realiza diferentes processos, primeiro faz a
trimagem por qualidade segundo os par√¢metros customizados pelo usu√°rio,
depois far√° a uni√£o dos dois reads (forward e reverse), seguido far√° o
denoising (elimina√ß√£o de erros) e por √∫ltimo a remo√ß√£o de chimeras. Se
quiser conhecer mais sobre todos os par√¢mteros pra o DADA2 para
sequ√™ncias *paired-end*, d√≠gite `qiime dada2 denoised-paired --help`,
para abrir o men√∫ de ajuda no terminal.

Considerando que o fragmento sequenciado (regi√£o V4) tem um tamanho
aproximado de 290 bp, e as leituras de 250 bp, temos uma sobreposi√ß√£o de
210 bp. Isto √© importante ter em conta na hora de fazer a trimagem, pois
√© necess√°rio ter no m√≠nimo 20 bp de sobreposi√ß√£o.

    qiime dada2 denoise-paired --i-demultiplexed-seqs 01.ReadsQza/trimmedreads.qza \
                               --p-trunc-len-f 200 \
                               --p-trunc-len-r 200 \
                               --p-max-ee-f 2 \
                               --p-n-threads 10 \
                               --output-dir 02.DADA2

Agora, d√™ uma olhada na tabela dos counts, para determinar quantas
sequ√™ncias sobreviveram ao processo de denoising:

    qiime tools export --input-path 02.DADA2/denoising_stats.qza --output-path 02.DADA2/

Para ver las estat√≠sticas use `nano`

    nano 02.DADA2/stats.tsv

### 4.1 Resumindo onoutput do DADA2

Depois de rodar o DADA2, voc√™ pode resumir a tabela do denoising,
criando um artefato de visualiza√ß√£o `.qzv`:

    qiime feature-table summarize \
       --i-table 02.DADA2/table.qza \
       --o-visualization 02.DADA2/dada2_table_summary.qzv

Este resumo √© necess√°rio para determinar os *cut-offs* de filtragem que
ser√£o usados mais para frente.

## 5. Prepara√ß√£o das Bases de Dados

O plugin *RESCRIPt* ser√° usado para a formata√ß√£o, gest√£o e manipula√ß√£o
de sequ√™ncias de refer√™ncia. Ser√£o formatadas la bases de datos **SSU
Silva N99** e **GTDB** (*Genome Taxonomy Data Bases*).

### 5.1 Silva Databases

O seguinte comando ir√° realizar todos os passos para obter a base de
dados Silva pronta para usar em Qiime2. O comando descarrega os arquivos
usando `wget`, depois descomprime usando `gzip`, seguido da importa√ß√£o
em artefatos Qiime2, por √∫ltimo *RESCRIPt* prepara a base de dados para
trabalhar com Qiime2.

Para obter a √∫ltima atualiza√ß√£o (release 138.1 - Agosto 27, 2020), rode
o seguinte comando:

    # Crie um diret√≥rio pras DBs
    mkdir dbs
    mkdir dbs/silva

    # Entre no diret√≥rio
    cd dbs/silva/

    # RESCRIPt
    qiime rescript get-silva-data \
        --p-version '138.1' \
        --p-target 'SSURef_NR99' \
        --p-include-species-labels \
        --p-rank-propagation \
        --o-silva-sequences silva-138.1-ssu-nr99-seqs.qza \
        --o-silva-taxonomy silva-138.1-ssu-nr99-tax.qza

Agora, voc√™ tem uma base de dados Silva *ready-to-use* com Qiime2,
por√©m, √© o gene 16S rRNA completo. Voc√™ pode realizar alguns passos
extra para limpar e preparar uma nova base de dados baseado nos primers
usados pro sequenciamento de suas amostras. Neste tutorial, somenta ser√°
preparada a base de dados baseada nos primers usados para o
sequenciamento das amostras exemplo (regi√£o V4).

#### 5.1.1 Filtrando sequ√™ncias com baixa qualidade

No seguinte comando, ir√£o ser filtradas sequ√™ncias com cinco ou mais
bases ambiguas e qualquer homopolimeros com oito ou mais bases de
cumprimento.

    qiime rescript cull-seqs \
        --i-sequences silva-138.1-ssu-nr99-seqs.qza \
        --o-clean-sequences silva-138.1-ssu-nr99-seqs-cleaned.qza

#### 5.1.2 Filtrando sequ√™ncias por tamanho e taxonomia

Neste etapa ser√£o removidas sequ√™ncias curtas. Por√©m, muitas sequ√™ncias
de rRNA de archaeas e algumas de bact√©rias t√™m um cumprimento menor de
1000 ou 1200 bp. Por tanto √© necess√°rio filtrar pela taxonomia. Assim,
as sequ√™ncias que \***n√£o** cumpram os seguintes par√¢metros, ser√£o
removidas: Archaea (16S) ‚ÄÑ&gt;‚ÄÑ‚ÄÑ=‚ÄÑ900 bp, Bacteria (16S) ‚ÄÑ&gt;‚ÄÑ‚ÄÑ=‚ÄÑ1200
bp, and any Eukayota (18S) ‚ÄÑ&gt;‚ÄÑ‚ÄÑ=‚ÄÑ1400 bp.

    qiime rescript filter-seqs-length-by-taxon \
        --i-sequences silva-138.1-ssu-nr99-seqs-cleaned.qza \
        --i-taxonomy silva-138.1-ssu-nr99-tax.qza \
        --p-labels Archaea Bacteria Eukaryota \
        --p-min-lens 900 1200 1400 \
        --o-filtered-seqs silva-138.1-ssu-nr99-seqs-filt.qza \
        --o-discarded-seqs silva-138.1-ssu-nr99-seqs-discard.qza

#### 5.1.3 Derepli√ß√£o de sequ√™ncias e taxonomia

Podem existir sequ√™ncias identicas na base de dados com taxonomia igual
ou diferente.Ent√£o, ir√£o ser removidas as sequ√™ncias redundantes, H√°
diferentes abordagens para a dereplica√ß√£o e sua escolha depende de seus
objetivos, ent√£o, por favor leia o [tutorial dos desenvolvedores de
RESCRIPt](https://forum.qiime2.org/t/processing-filtering-and-evaluating-the-silva-database-and-other-reference-sequence-data-with-rescript/15494#heading--second-header)
(veja a se√ß√£o *Dereplication of sequences and taxonomy*).

No seguinte exemplo, rodar√° o modo `uniq`, o qual ret√©m sequ√™ncias
identicas com diferentes taxonomias.

    qiime rescript dereplicate \
        --i-sequences silva-138.1-ssu-nr99-seqs-filt.qza  \
        --i-taxa silva-138.1-ssu-nr99-tax.qza \
        --p-rank-handles 'silva' \
        --p-mode 'uniq' \
        --o-dereplicated-sequences silva-138.1-ssu-nr99-seqs-derep-uniq.qza \
        --o-dereplicated-taxa silva-138.1-ssu-nr99-tax-derep-uniq.qza

A continua√ß√£o, voc√™ tem que rodar o comando para criar o *classifier*
filtrado, e dereplicado do gene 16S rRNA completo:

    qiime feature-classifier fit-classifier-naive-bayes \
      --i-reference-reads  silva-138.1-ssu-nr99-seqs-derep-uniq.qza \
      --i-reference-taxonomy silva-138.1-ssu-nr99-tax-derep-uniq.qza \
      --o-classifier silva-138.1-ssu-nr99-classifier.qza

#### 5.1.4 *Classifier* para uma regi√£o espec√≠fica

Alguns estudos como ([Werner *et al.*
2011](http://dx.doi.org/10.1038/ismej.2011.82) e [Bokulich *et al.*
2018](http://dx.doi.org/10.1186/s40168-018-0470-z)) mostraram que
treinar as bases de dados para uma regi√£o espec√≠fica melhora a robustez
da assigna√ß√£o taxon√¥mica. Assim, neste tutorial se recomienda fortemente
treinar sua base de dados com os mesmo primers usados no sequenciamento.
O processo consiste em extrair da base de dados a regi√£o espec√≠fica
flanqueada pelos primers.

Ent√£o, ser√£o usados os primers para a regi√£o V4 (515F-806R) e a base de
dados do gene completo dereplicada obtida no √∫ltimo passo. H√° duas
coisas para ter especial cuidado, primeiro, as sequ√™ncias dos primers
devem ser colocados em dire√ß√£o *5‚Äô-3‚Äô* (como eles foram pedidos para
serem sintetizados) e, segundo, √© necess√°rio definir como
`--p-read-orientation 'forward'`, porque la base de dados SILVA √© curada
para estar na mesma dire√ß√£o.

Agora, rode o seguinte comando:

    qiime feature-classifier extract-reads \
        --i-sequences silva-138.1-ssu-nr99-seqs-derep-uniq.qza \
        --p-f-primer GTGYCAGCMGCCGCGGTAA \
        --p-r-primer GGACTACNVGGGTWTCTAAT \
        --p-n-jobs 2 \
        --p-read-orientation 'forward' \
        --o-reads silva-138.1-ssu-nr99-seqs-515f-806r.qza

#### 5.1.5 Dereplica√ß√£o da regi√£o espec√≠fica

√â necess√°rio dereplicar novamente, porque depois da extra√ß√£o da regi√£o
espec√≠fica, muitas das sequ√™ncias ser√£o identicas.

    qiime rescript dereplicate \
        --i-sequences silva-138.1-ssu-nr99-seqs-515f-806r.qza \
        --i-taxa silva-138.1-ssu-nr99-tax-derep-uniq.qza \
        --p-rank-handles 'silva' \
        --p-mode 'uniq' \
        --o-dereplicated-sequences silva-138.1-ssu-nr99-seqs-515f-806r-uniq.qza \
        --o-dereplicated-taxa  silva-138.1-ssu-nr99-tax-515f-806r-derep-uniq.qza

Agora, novamente treine o novo *classifier*.
`qiime feature-classifier fit-classifier-naive-bayes \     --i-reference-reads silva-138.1-ssu-nr99-seqs-515f-806r-uniq.qza \     --i-reference-taxonomy silva-138.1-ssu-nr99-tax-515f-806r-derep-uniq.qza \     --o-classifier silva-138.1-ssu-nr99-515f-806r-classifier.qza`

> > Se voc√™ estiver interessado, no [tutorial do
> > RESCRIPt](https://forum.qiime2.org/t/processing-filtering-and-evaluating-the-silva-database-and-other-reference-sequence-data-with-rescript/15494)
> > h√° outras opera√ß√µes com bases de dados, como *databases evaluation
> > functions*, *orient sequences by alignment to reference*, *reverse
> > transcribe*, *editing taxonomy*, entre outras.

### 5.2 GTDB Databases

Voc√™ pode usar outras bases de dados como **GTDB** ou **NCBI**. Neste
tutorial ser√£o abordados os passos para construir um **classifier**
usando a base de dados **GTDB**.

#### 5.2.1 Descargando as dbs

O primeiro passo √© descarregar as bases de dados de bact√©rias e archaeas
(release 202) usando o comando `wget`.

    # Crie um diret√≥rio para gtdb
    cd ..
    mkdir gtdb

    # entre ao diret√≥rio
    cd gtdb/

    # Archaeas: sequ√™ncias
    wget https://data.gtdb.ecogenomic.org/releases/release202/202.0/genomic_files_reps/ar122_ssu_reps_r202.tar.gz

    # Archaeas: taxonomia
    wget https://data.gtdb.ecogenomic.org/releases/release202/202.0/ar122_taxonomy_r202.tsv

    # Archaeas: √°rvore
    wget https://data.gtdb.ecogenomic.org/releases/release202/202.0/ar122_r202.tree

    # Bact√©rias: sequ√™ncias
    wget https://data.gtdb.ecogenomic.org/releases/release202/202.0/genomic_files_reps/bac120_ssu_reps_r202.tar.gz

    # Bact√©rias: taxonomia
    wget https://data.gtdb.ecogenomic.org/releases/release202/202.0/bac120_taxonomy_r202.tsv

    # Bact√©rias: √°rvore
    wget https://data.gtdb.ecogenomic.org/releases/release202/202.0/bac120_r202.tree

Agora, voc√™ vai ter um arquivo de texto com as taxonomias e um arquivo
`.fna` com as sequ√™ncias representativas de bact√©rias e de archaeas.
Para come√ßar o processo de treinamento √© necess√°rio descomprimir os
arquivos das sequ√™ncias, usando o comando `gunzip`.

    gunzip ar122_ssu_reps_r202.tar.gz
    tar -xvf ar122_ssu_reps_r202.tar

    gunzip bact120_ssu_reps_r202.tar.gz
    tar -xvf bact120_ssu_reps_r202.tar

Ap√≥s descarregar e descomprimir as dbs, agoraa √© necess√°rio unir a
database de bact√©rias e archaeas, usando o comando `cat`.

    # Concatene as sequ√™ncias
    cat ar122_ssu_reps_r202.fna bac120_ssu_reps_r202.fna > full_seq_GTDB_r202.fna

    # Concatene as tabelas de taxonomia
    cat ar122_taxonomy_r202.tsv bac120_taxonomy_r202.tsv > full_taxonomy_r202.tsv

#### 5.2.2 Importanto como artefato `.qza`

Importe as sequ√™ncias da DB completa (Bact√©rias + Archaeas), usando o
comando `qiime tools import`

    qiime tools import  \
        --type 'FeatureData[Sequence]'  \
        --input-path full_seq_GTDB_r202.fna  \
        --output-path full_seq_GTDB_r202.qza

Importe as taxonomias da DB completa:

    qiime tools import  \
        --type 'FeatureData[Taxonomy]'  \
        --input-path full_taxonomy_r202.tsv  \
        --output-path full_taxonomy_r202.qza  \
        --input-format HeaderlessTSVTaxonomyFormat

#### 5.2.3 Filtrando sequ√™ncias com baixa qualidade

Ap√≥s obter a DB completa importada como `.qza`, √© poss√≠vel aplicar os
comandos do **RESCRIPt** para limpar e dereplicar a DB, ao igual que foi
feito com a base de dados Silva. No seguinte comando, ir√£o ser filtradas
sequ√™ncias com cinco ou mais bases ambiguas e qualquer homopolimeros com
oito ou mais bases de cumprimento.

    qiime rescript cull-seqs \
        --i-sequences full_seq_GTDB_r202.qza \
        --o-clean-sequences full_seq_GTDB_r202-cleaned.qza

#### 5.2.4 Filtrando sequ√™ncias por tamanho e taxonomia

Neste etapa ser√£o removidas sequ√™ncias curtas. Por√©m, muitas sequ√™ncias
de rRNA de archaeas e algumas de bact√©rias t√™m um cumprimento menor de
1000 ou 1200 bp. Por tanto √© necess√°rio filtrar pela taxonomia. Assim,
as sequ√™ncias que \***n√£o** cumpram os seguintes par√¢metros, ser√£o
removidas: Archaea (16S) ‚ÄÑ&gt;‚ÄÑ‚ÄÑ=‚ÄÑ900 bp, Bacteria (16S) ‚ÄÑ&gt;‚ÄÑ‚ÄÑ=‚ÄÑ1200
bp, and any Eukayota (18S) ‚ÄÑ&gt;‚ÄÑ‚ÄÑ=‚ÄÑ1400 bp.

    qiime rescript filter-seqs-length-by-taxon \
        --i-sequences full_seq_GTDB_r202-cleaned.qza \
        --i-taxonomy full_taxonomy_r202.qza \
        --p-labels Archaea Bacteria Eukaryota \
        --p-min-lens 900 1200 1400 \
        --o-filtered-seqs full_seq_GTDB_r202-filt.qza \
        --o-discarded-seqs full_seq_GTDB_r202-discard.qza

#### 5.2.5 Derepli√ß√£o de sequ√™ncias e taxonomia

Podem existir sequ√™ncias identicas na base de dados com taxonomia igual
ou diferente.Ent√£o, ir√£o ser removidas as sequ√™ncias redundantes, H√°
diferentes abordagens para a dereplica√ß√£o e sua escolha depende de seus
objetivos, ent√£o, por favor leia o [tutorial dos desenvolvedores de
RESCRIPt](https://forum.qiime2.org/t/processing-filtering-and-evaluating-the-silva-database-and-other-reference-sequence-data-with-rescript/15494#heading--second-header)
(veja a se√ß√£o *Dereplication of sequences and taxonomy*).

No seguinte exemplo, rodar√° o modo `uniq`, o qual ret√©m sequ√™ncias
identicas com diferentes taxonomias.

    qiime rescript dereplicate \
        --i-sequences full_seq_GTDB_r202-filt.qza  \
        --i-taxa full_taxonomy_r202.qza \
        --p-rank-handles 'gtdb' \
        --p-mode 'uniq' \
        --o-dereplicated-sequences full_seq_GTDB_r202-derep-uniq.qza \
        --o-dereplicated-taxa full_taxonomy_r202-derep-uniq.qza

A continua√ß√£o, voc√™ tem que rodar o comando para criar o *classifier*
filtrado, e dereplicado do gene 16S rRNA completo no GTDB:

    qiime feature-classifier fit-classifier-naive-bayes \
      --i-reference-reads  full_seq_GTDB_r202-derep-uniq.qza\
      --i-reference-taxonomy full_taxonomy_r202-derep-uniq.qza \
      --o-classifier full_taxonomy_r202-classifier.qza

#### 5.2.6 *Classifier* para uma regi√£o espec√≠fica

Ao igual que com a base de dados do Silva, ir√£o ser extraidas as
sequ√™ncias da regi√£o espec√≠fica que foi sequenciada nas amostras, no
caso deste tutorial a regi√£o V4.

Agora, rode o seguinte comando:

    qiime feature-classifier extract-reads \
        --i-sequences full_seq_GTDB_r202-derep-uniq.qza \
        --p-f-primer CCTACGGGNGGCWGCAG \
        --p-r-primer GACTACHVGGGTATCTAATCC \
        --p-n-jobs 2 \
        --p-read-orientation 'forward' \
        --o-reads GTDB_r202-341f-785r.qza

#### 5.2.7 Dereplica√ß√£o da regi√£o espec√≠fica

√â necess√°rio dereplicar novamente, porque depois da extra√ß√£o da regi√£o
espec√≠fica, muitas das sequ√™ncias ser√£o identicas.

    qiime rescript dereplicate \
        --i-sequences GTDB_r202-341f-785r.qza \
        --i-taxa full_taxonomy_r202-derep-uniq.qza \
        --p-rank-handles 'gtdb' \
        --p-mode 'uniq' \
        --o-dereplicated-sequences GTDB_r202-341f-785r-uniq.qza \
        --o-dereplicated-taxa  GTDB_r202-341f-785r-tax-341f-785r-derep-uniq.qza

Agora, novamente treine o novo *classifier*.
`qiime feature-classifier fit-classifier-naive-bayes \     --i-reference-reads GTDB_r202-341f-785r-uniq.qza  \     --i-reference-taxonomy GTDB_r202-341f-785r-tax-341f-785r-derep-uniq.qza \     --o-classifier GTDB_r202-341f-785r-tax-341f-785r-classifier.qza`

Finalmente, voc√™ agora t√™m quatro classificadores (bases de dados
prontas):

-   `silva-138.1-ssu-nr99-classifier.qza`: Base de dados Silva, gene 16S
    rRNA completo
-   `silva-138.1-ssu-nr99-515f-806r-classifier.qza`: Base de dados
    Silva, regi√£o V4 do gene 16S rRNA
-   `full_taxonomy_r202-classifier.qza`: Base de dados GTDB, gene 16S
    rRNA completo
-   `GTDB_r202-515f-806r-tax-515f-806r-classifier.qza`: Base de dados
    GTDB, regi√£o V4 do gene 16S rRNA.

## 6. Classifica√ß√£o Taxon√¥mica

Ap√≥s obtidas e treinadas as bases de dados, agora pode ser rodado o
comando para a asigna√ß√£o taxon√¥mica das ASVs obtidas com DADA2. Voc√™
pode usar o classificador com o gene completo ou s√≥ com a regi√£o que foi
sequenciada nas suas amostras. Para este caso, foi a regi√£o V4 (515 -
806).

Neste tutorial, ser√£o usados os dois classificadores, do Silva e do
GTDB, para fazer uma compara√ß√£o das bases de dados

### 6.1. SILVA

    qiime feature-classifier classify-sklearn \
       --i-reads 02.DADA2/representative_sequences.qza \
       --i-classifier ../dbs/silva/silva-138.1-ssu-nr99-515-806-classifier.qza \
       --p-n-jobs 6 \
       --output-dir 03.SilvaClassification

Ap√≥s obter a classifica√ß√£o taxon√¥mica, pode exportar o artefato `.qza`
em formato tabular `.tsv`

    qiime tools export \
       --input-path 03.SilvaClassification/classification.qza --output-path 03.SilvaClassification
       
    # D√™ uma olhada na tabela taxonomy.tsv
    nano 03.SilvaClassification/taxonomy.tsv

Com o comando anterior foi criado uma tabela chamada `taxonomy.tsv`,
onde a primeira coluna corresponde aos ASVs e a segunda √† classifica√ß√£o
taxon√¥mica.

### 6.3. GTDB

    qiime feature-classifier classify-sklearn \
       --i-reads 02.DADA2/representative_sequences.qza \
       --i-classifier ../dbs/gtdb/GTDB_r202-515f-806r-tax-515f-806r-classifier.qza \
       --p-n-jobs 6 \
       --output-dir 04.GTDBClassification

Ap√≥s obter a classifica√ß√£o taxon√¥mica, pode exportar o artefato `.qza`
em formato tabular `.tsv`

    qiime tools export \
       --input-path 04.GTDBClassification/classification.qza --output-path 04.GTDBClassification
       
    # D√™ uma olhada na tabela taxonomy.tsv
    nano 04.GTDBClassification/taxonomy.tsv

Com o comando anterior foi criado uma tabela chamada `taxonomy.tsv`,
onde a primeira coluna corresponde aos ASVs e a segunda √† classifica√ß√£o
taxon√¥mica.

### 6.4. Cross checking com Blast

Com o intuito de checar a acur√°cia da classifica√ß√£o taxon√¥mica, √©
recomendado fazer um cross checking com *BLASTn* usando algumas ASVs.
Par aisto, primeiro deve transformar o artefato `classification.qza`
para visualiza√ß√£o `.qzv`, usando o seguinte comando:

    qiime feature-table tabulate-seqs --i-data 02.DADA2/representative_sequences.qza \
                                      --o-visualization 02.DADA2/representative_sequences.qzv
                                      
    # liste os objetos dentro 02.DADA2
    ls 02.DADA2

Descarregue o arquivo `02.DADA2/representative_sequences.qzv` para dar
uma olhada nele usando [qiime2 viewer](https://view.qiime2.org/).
Escolha \~5 ASVs para *blastar*, de diferentes grupos taxon√¥micos (p.e.
diferentes filos), de acordo com a classifica√ß√£o taxon√¥mica
(`03.SilvaClassification/taxonomy.tsv` ou
`04.GTDBClassification/taxonomy.tsv`).

## 7. Filtragem

Para a an√°lise de microbiomas √© importante filtrar a tabela da sa√≠da do
*denoising*. Aqui, n√£o ser√£o aplicados filtros, por√©m se quiser aplicar
no seus dados,
[here](https://docs.qiime2.org/2020.8/tutorials/filtering/) encontra
mais detalhes. √â poss√≠vel filtra, ASVs raros, contaminantes (p.e.
mitocondrias, cloroplastos), no clasificados, amostras com baixa
profundidade de sequenciamento.

## 8. √Årvore filogen√©tica

O plugin **fasttree** √© usado para colocar pequenas sequ√™ncias dentro de
uma √°rvore filogen√©tica. Esta √© um jeito √∫til de determinar a √°rvore
filogen√©tica para as ASVs encontradas. A continua√ß√£o se encontram uma
s√©rie de comandos para a constru√ß√£o da √°rvore, com as seguintes etapas:
Alinhamento m√∫ltiplo com MAFFT e constru√ß√£o da √°rvore com Fasttree

**Alinhamento m√∫ltiplo**

    ## Crie um diret√≥rio para guardar a √°rvore
    mkdir 05.PhylogeneticTree

    ## Primeiro voc√™ vai fazer um alinhamento m√∫ltiplo com MAFFT
    qiime alignment mafft --i-sequences  02.DADA2/representative_sequences.qza \
                            --p-n-threads 6 \
                            --o-alignment 05.PhylogeneticTree/rep_seqs_aligned.qza

    ## Masking
    qiime alignment mask --i-alignment  05.PhylogeneticTree/rep_seqs_aligned.qza \
                           --o-masked-alignment 05.PhylogeneticTree/rep_seqs_aligned_masked.qza

**Construindo a √°rvore**

    ## Constuir a √°rvore com FastTree
    qiime phylogeny fasttree --i-alignment 05.PhylogeneticTree/rep_seqs_aligned_masked.qza \
                             --p-n-threads 4 \
                             --o-tree 05.PhylogeneticTree/rep_seqs_aligned_masked_tree.qza

    ## Enrai√ßar a √°rvore

    qiime phylogeny midpoint-root --i-tree  05.PhylogeneticTree/rep_seqs_aligned_masked_tree.qza \
                                  --o-rooted-tree 05.PhylogeneticTree/rep_seqs_aligned_masked_tree_rooted.qza
    ## Exportar a √°rvore
    qiime tools export /
    --input-path 05.PhylogeneticTree/rep_seqs_aligned_masked_tree_rooted.qza \
    --output-path 05.PhylogeneticTree/

Ao final do processo, voc√™ obteve uma √°rvore filogen√©tica com todas as
ASVs `tree.nwk`.

## 9. Gr√°ficos

Usando **Qiime2** √© poss√≠vel gerar alguns gr√°ficos muito f√°cil. Em
primer lugar e para aproveitar muito mais os recursos do gr√°ficos do
Qiime2, √© necess√°rio gerar um arquivo com os metadados. Use `nano` para
gerar um arquivo `.txt`, o qual ser√° organizado em colunas com
informa√ß√µes e caracter√≠sticas das amostras.

    nano sample-metadata.txt

Para o caso das amostras que foram processadas neste tutorial, seguem os
metadados:

    Sample-id   SampleName    StageOfTreatment    Local   Season
    #q2:types   categorical   categorical   categorical   categorical
    STI1-Apr19    SepticTank    SepticTank    Factory   Autumn
    STI1-Jan19    SepticTank    SepticTank    Factory   Summer
    STI1-Oct19    SepticTank    SepticTank    Factory   Spring
    AFI1-Jan19    AnaerobicFilter   AnaerobicFilter   Factory   Summer
    AFI1-Apr19    AnaerobicFilter   AnaerobicFilter   Factory   Autumn
    AFI1-Oct18    AnaerobicFilter   AnaerobicFilter   Factory   Spring

A primeira coluna √© obrigat√≥ria, as demais colunas dependem dos dados.
Entre mais colunas e mais caracter√≠sticas melhor. A segunda linha √©
obrigat√≥ria tamb√©m, cont√©m o tipo de vari√°vel da coluna (p.e.
categorical, numeric).

### 9.1. BarPlot

Crie um barplot para a classifica√ß√£o taxon√¥mica feita com Silva e outro
para GTDB.

A continua√ß√£o se encontra o comando:

    mkdir 06.Graphs

    # Para a base de dados Silva
    qiime taxa barplot \
    --i-table 02.DADA2/table.qza \
    --i-taxonomy 03.SilvaClassification/classification.qza \
    --m-metadata-file sample-metadata.txt \
    --o-visualization 06.Graphs/taxa_barplots_silva.qzv

    # Para a base de dados GTDB
    qiime taxa barplot \
    --i-table 02.DADA2/table.qza \
    --i-taxonomy 004.GTDBClassification/classification.qza \
    --m-metadata sample-metadata.txt \
    --o-visualization 06.Graphs/taxa_barplots_gtdb.qzv

Use [qiime2 view](https://view.qiime2.org) para ver los barplots
gerados. A√≠ voc√™ pode modificar a escala de cores, a ordem das amostras,
o n√≠vel taxon√¥mico e tamb√©m pode salvar o gr√°fico em distintos formatos
para publica√ß√£o.

### 9.2. Curvas de rarefa√ß√£o

As curvas de rarefa√ß√£o s√£o muito importantes, porque elas permitem
observar se o sequenciamento fue suficiente para amostrar toda a
diversidade presente nas amostras. No eixo x, est√£o o n√∫mero de
sequ√™ncias e no eixo y, o n√∫mero de ASVs. O ideal √© alcan√ßar o *plateau*
em todas as amostras, pois isto significa que n√£o importa quantas mais
sequ√™ncias existam (direita do eixo x), n√£o apareceram novas ASVs (eixo
y). Isto quer dizer que chegou √† satura√ß√£o da amostra (estas curvas
tamb√©m podem ser encontradas como curvas de satura√ß√£o), por tanto foi
poss√≠vel amostrar toda a diversidade da amostra. Se por algum acaso n√£o
se chega no *plateau* quer dizer que √© necess√°rio mais sequenciamento
(ou mais amostra) para conseguir atingir toda a diversidade da amostra.

Use o arquivo `02.DADA2/dada2_table_summary.qzv` para determinar o menor
n√∫mero de ASVs encontrados por amostra, para usar como corte. No caso
deste tutorial a amostra **STI1-Oct18** tem o menor n√∫mero de ASVs
(87,615).

A continua√ß√£o se encontra o comando para a gera√ß√£o das curvas de
rarefa√ß√£o:

    qiime diversity alpha-rarefaction \
    --i-table 02.DADA2/table.qza \
    --p-max-depth 87615 \
    --p-steps 10 \
    --m-metadata-file sample-metadata.txt \
    --o-visualization 06.Graphs/rarefaction_curves.qzv

Use novamente [qiime2 view](https://view.qiime2.org) para observar as
curvas. Ir√° encontrar a curva gerada com duas m√©tricas, shannon, a qual
√© uma m√©trica que quantifica a diversidade e com observed\_features ou
ASVs.

Como pode ser observado nas amostras do tutorial, todas atingiram o
*plateau*, por tanto o esfor√ßo amostral foi suficiente para acessar a
toda a diversidade microbiana das amostras.

### 9.3 An√°lise de Alfa e Beta diversidade

Antes de continuar √© muito importante voc√™ entender que √© alfa e beta
diversidade, as diferentes m√™tricas usadas para a an√°lises e compara√ß√µes
de microbiomas e at√© testes estat√≠sdicos adequados para este tipo de
dados.

Aqui s√≥ alguns links e refer√™ncias recomendados para voc√™ revisar antes
de continuar:

-   Alpha and beta diversity metrics [Magurran AE. Measuring biological
    diversity: John Wiley & Sons,
    2013](https://www.evolution.unibas.ch/walser/bacteria_community_analysis/2015-02-10_MBM_tutorial_combined.pdf)
    [GUide to STatistical Analysis in Microbial Ecology (GUSTA
    ME)!](https://sites.google.com/site/mb3gustame/home)

Aqui um resum√£o do maisss b√°sico ü§ì

**Alfa diversidade (Dentro das amostras)**

**Riqueza de esp√©cies,** quantas esp√©cies ou ASVs diferentes podemos
detectar em cada amostra? *M√™tricas:* Esp√©cies observadas
(observed\_otus), ACE, Chao1.

**Diversidade de esp√©cies (Shannon index)** ‚ÄúHow different?‚Äù Como est√£o
distribuidos (equilibrados) est√£o os microrganismos entre si? Temos
uniformidade de esp√©cies (n√≠vel de abund√¢ncia semelhante) ou algumas
esp√©cies dominam mais que outras? **M√™tricas:** Shannon, Simpson.

**Beta diversity (Entre as amostra)**

Qu√£o diferente √© a composi√ß√£o microbiana em um ambiente (amostra) em
compara√ß√£o com outro(a)?

A beta diversidade mostra a diferen√ßa entre comunidades microbianas de
diferentes ambientes (amostras). O foco principal est√° na diferen√ßa nos
perfis de abund√¢ncia taxon√¥mica de diferentes amostras.

**M√™tricas:**

-   Bray‚ÄìCurtis dissimilarity

Baseada na abund√¢ncia ou read count Diferen√ßas das abund√¢ncias
microbianas entre duas amostras (p.e. A n√≠vel de esp√©cie) Valores desde
0 a 1 0 significa que ambas amostras compartilham a mesma esp√©cie
exatamente na mesma abund√¢ncia. 1 significa que ambas amostras t√™m
esp√©cies e abund√¢ncias totalmente diferentes.

-   Jaccard distance

Baseada na presen√ßa ou aus√™ncia de esp√©cies (N√£o leva em conta a
informa√ß√£o de abund√¢ncia) Diferen√ßas na composi√ß√£o microbiana entre duas
amostras 0 significa que ambas amostras compartilham exatamente as
mesmas esp√©cies. 1 significa que ambas amostras n√£o tem nenhuma esp√©cie
em comum UniFrac

**Dist√¢ncias filogen√©ticas (√°rvore filogen√©tica)** Baseada no
comprimento da ramifica√ß√£o compartilhada entre duas amostras ou
exclusiva para uma ou outra amostra.

**unweighted UniFrac:** baseado s√≥ em dist√¢ncias filogen√©ticas (N√£o leva
em conta a informa√ß√£o de abund√¢ncia)

**weighted UniFrac:** os comprimentos dos ramos s√£o ponderados por
abund√¢ncia relativa (inclui informa√ß√µes filogen√©ticas e de abund√¢ncia)

Com o seguinte conjunto de comandos ser√£o gerados vetores com cada uma
das m√™tricas dispon√≠veis no qiime2:

    ## Core metrics
    qiime diversity core-metrics-phylogenetic \
    --i-table 02.DADA2/table.qza \
    --p-sampling-depth 87615 \
    --m-metadata-file sample-metadata.txt \
    --i-phylogeny 05.PhylogeneticTree/rep_seqs_aligned_masked_tree_rooted.qza \
    --output-dir 07.AlphaBetaDiversity

    ## Para Chao1
    qiime diversity alpha \
    --i-table 02.DADA2.table.qza \
    --p-metric chao1 \
    --o-alpha-diversity 07.AlphaBetaDiversity/chao1_vector.qza

    ## Para Simpson
    qiime diversity alpha \
    --i-table 02.DADA2.table.qza \
    --p-metric simpson \
    --o-alpha-diversity 07.AlphaBetaDiversity/simpson_vector.qza

Depois de rodar os comandos anteriores, ir√° obter bastantes arquivos,
que contem vetores com as m√©tricas de alfa diversidade usadas
(i.e.¬†faith\_pd, observed\_features, shannon, evenness, chao1 e
simpson), e matrizes de dist√¢ncias con m√©tricas de beta diversidade como
unifrac, jaccard e bray\_curtis. Destes √∫ltimos tamb√©m encontrar√° as
visualiza√ß√µes 3D (p.e. `bray_curtis_emperor.qzv`).

Para facilitar a avalia√ß√£o ser√° construida uma tabela com algumas das
mais importantes m√©tricas de alfa diversidade:

    qiime metadata tabulate --m-input-file sample-metadata.txt \
    --m-input-file 07.AlphaDiversity/shannon_vector.qza \
    --m-input-file 07.AlphaDiversity/observed_features_vector.qza \
    --m-input-file 07.AlphaDiversity/simpson_vector.qza \
    --m-input-file 07.AlphaDiversity/chao1_vector.qza \
    --o-visualization 07.AlphaDiversity/alfadiversidade_all.qzv \

O arquivo de sa√≠da deste comando pode ser carregado no [qiime2
view](https://view.qiime2.org). √â uma tabela interativa com os metadados
e as m√©tricas de alfa diversidade. Pode ser descarregada em formato
`.tsv`

Os gr√°ficos de Beta diversidade (arquivos terminados em `_emperor_qzv`),
tamb√©m podem ser carregados um por um no [qiime2
view](https://view.qiime2.org). S√£o gr√°ficos 3D, que podem ser
customizados, baseado nos metadados. Podem ser descarregados em formato
`.png` ou `.svg`, perdendo as caracter√≠sticas tridimensionais.

## 10. Exporta√ß√£o final de arquivos

Os arquivos finais necess√°rios para continuar as an√°lises em outros
softwares s√£o:

-   `table.qza`: √© uma tabela com as frequ√™ncias das ASVs (linhas) em
    cada amostra (colunas).

-   `taxonomyclassification.qza`: √© uma tabela com a taxonomia (colunas)
    de cada ASV (linhas).

-   `tree.nwk`: √°rvore filogen√©tica.

Os dois primeiros devem ser transformados a `.tsv`:

    # Crie um diret√≥rio para os arquivos finais
    mkdir 08.ExportFiles

    # Transformando de .qza para .biom
    qiime tools export \
    --input-path 02.DADA2/table.qza \
    --output-path 08.ExportFiles

    # Transformando de .biom para .tsv
    biom convert \
    -i 08.ExportFiles/feature-table.biom \
    -o 08.ExportFiles/ASV_table.tsv \
    --to-tsv \
    --table-type "OTU table"

Usando `nano`, abra o arquivo gerado `ASV_table.tsv` e apague a primeira
linha (\#contructed from a biom file) e troque \#OTU ID por OTUID.

Para exportar a tabela de taxonomia:

    # Taxonomia com silva
    qiime tools export --input-path 03.SilvaClassification/classification.qza --output-path 08.ExportFiles/

    mv 08.ExportFiles/taxonomy.tsv 08.ExportFiles/taxonomy_silva.tsv

    # Taxonomia com GTDB
    qiime tools export --input-path 04.GTDBClassification/classification.qza --output-path 08.ExportFiles/

    mv 08.ExportFiles/taxonomy.tsv 08.ExportFiles/taxonomy_gtdb.tsv

Abra arquivo e troque Feature ID por OTUID.

------------------------------------------------------------------------

# II Metataxonomica com DADA2

O processamento de sequ√™ncias do gene 16S rRNA pode ser feito usando a
linguagem R, diretamente no IDE R Studio, com o pacote DADA2.

## 0. Instala√ß√µes

### 0.1. Intala√ß√£o R

A primeira etapa √© a instala√ß√£o do software R. Esta linguagem √©
*open-source*, gratuita e amplamente usada.

-   [R v4.1.2 para Windows
    10](https://vps.fmvz.usp.br/CRAN/bin/windows/base/R-4.1.2-win.exe)

-   [R v4.1.2 para
    MacOS](https://cran.r-project.org/bin/macosx/base/R-4.1.2.pkg)

-   [R v4.1.2 para Linux (Ubuntu)](https://vps.fmvz.usp.br/CRAN/)

### 0.2. Instala√ß√£o IDE RStudio

Para facilitar a intera√ß√£o do usu√°rio com a linguagem R, √© comum usar o
software chamado RStudio. O qual √© um ambiente de desenvolvimento
integrado (IDE) para a linguagem de programa√ß√£o R. Este programa tem uma
consola para digitar os c√≥digos, no entanto tamb√©m √© poss√≠vel interagir
com o programa com uma interfaz gr√°fica (bot√µes).

-   [RStudio 2021.09.2+382 para Windows
    10](https://download1.rstudio.org/desktop/windows/RStudio-2021.09.2-382.exe)

-   [RStudio 2021.09.2+382 para MasOS
    10.14+](https://download1.rstudio.org/desktop/macos/RStudio-2021.09.2-382.dmg)

-   [RStudio 2021.09.2+982 para Ubuntu
    18](https://download1.rstudio.org/desktop/bionic/amd64/rstudio-2021.09.2-382-amd64.deb)

### 0.3. Pacotes/Livrarias

Abra R atrav√©s de RStudio e instale os seguintes pacotes necess√°rios
para o tutorial. Basicamente um pacote do R √© uma conven√ß√£o para
organizar e padronizar a distribui√ß√£o de fun√ß√µes extras do R.

#### 0.3.1. Instala√ß√£o DADA2

-   **Instala√ß√£o desde Bioconductor**

``` r
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("dada2", version = "3.12")
```

-   **Instala√ß√£o desde a fonte**

``` r
install.packages("devtools")
library("devtools")
devtools::install_github("benjjneb/dada2", ref="v1.20")
```

Se as duas op√ß√µes de instala√ß√£o n√£o funcionam, consulte o [manual de
instala√ß√£o](https://benjjneb.github.io/dada2/dada-installation.html)
onde tem outros jeitos de instalar.

Para saber a vers√£o instalada:

``` r
library(dada2);packageVersion('dada2')
```

## 1. Remo√ß√£o de Primers com Cutadapt

### 1.1. Instala√ß√£o

[Cutadapt](https://cutadapt.readthedocs.io/en/stable/) √© uma ferramenta
para remo√ß√£o de adaptadores, primers, caudas poly-A e outros tipos de
sequ√™ncias indesej√°veis.

Instale **Cutadapt** usando Anaconda, atrav√©s da cria√ß√£o de um ambiente
virtual, chamado Bioinfo.

**Nota:** A organiza√ß√£o das amostras est√° na se√ß√£o 1 da primeira parte
deste tutorial [I Metataxon√¥mica com
Qiime2](https://github.com/khidalgo85/metataxonomics#i-metataxonomica-com-qiime2).

    # Crie o ambiente
    conda create -n Bioinfo

    # Ative o ambiente
    conda activate Bioinfo

    # Instale Cutadapt
    conda install -c bioconda cutadapt

### 1.2. Uso

Uma vez instalada a ferramenta, pode ser usada para a remo√ß√£o dos
primers, rodando o seguinte comando:

    # Crie uma pasta para a sa√≠da
    mkdir 01.PrimersTrim

    # Loop para Cutadapt
    for i in 00.RawData/*_1.fq.gz;
    do
    SAMPLE=$(basename $i _1.fq.gz)
    cutadapt --pair-filter any --no-indels -g "GTGYCAGCMGCCGCGGTAA" -G "GGACTACNVGGGTWTCTAAT" \
    --discard-untrimmed -o  01.PrimersTrim/${SAMPLE}_1.fq.gz \
    -p 01.PrimersTrim/${SAMPLE}_2.fq.gz > 01.PrimersTrim/${SAMPLE}_cutadapt_log.txt $i  00.RawData/${SAMPLE}_2.fq.gz
    done

**Explica√ß√£o do comando** O loop do comando anterior pega os dois pair
(`--pair-filter`) de amostra dentro de `00.RawData/` e remove os primers
espec√≠ficos usados para a amplifica√ß√£o das sequ√™ncias, definidos nos
par√¢metros `-g` (forward) e `-G` (reverse). Descarta as sequ√™ncias onde
n√£o foi encontrado o primer (`--discard-untrimmed`) e salva as
sequ√™ncias trimadas na pasta definida em `-o`. Al√©m, escreve arquivos
`.txt` com as estat√≠sticas da remo√ß√£o dos primers para cada amostra
(p.e. `sample1_cutadapt_log.txt`).

### 2. Processamento em R

A partir de agora os comandos e processos ser√£o rodados no R usando o
IDE RStudio. Ative o carregue as fun√ß√µes do pacote `dada2`, usando a
fun√ß√£o `library()`.

``` r
library(dada2); packageVersion("dada2")
#> Loading required package: Rcpp
#> [1] '1.22.0'
```

#### 2.1. Definiendo o diret√≥rio de trabalho

``` r
setwd("docs/") # Define o diret√≥rio de trabalho
```

#### 2.2. Carregando os dados no R

``` r
my.dir <- "docs/01.PrimersTrim" #cria a vari√°vel my.dir com o caminho ao diret√≥rio das amostras
list.files(my.dir) #Lista o conte√∫do do diret√≥rio
#>  [1] "filtered"         "sample10_1.fq.gz" "sample10_2.fq.gz" "sample12_1.fq.gz"
#>  [5] "sample12_2.fq.gz" "sample2_1.fq.gz"  "sample2_2.fq.gz"  "sample4_1.fq.gz" 
#>  [9] "sample4_2.fq.gz"  "sample6_1.fq.gz"  "sample6_2.fq.gz"  "sample7_1.fq.gz" 
#> [13] "sample7_2.fq.gz"

forwards <- sort(list.files(my.dir, pattern = "_1.fq.gz", full.names = TRUE)) # ordena, e lista os nomes dos arquivos que terminem com o padr√£o definido (pair 1/forwards), e salva na vari√°vel forwards

reverses <- sort(list.files(my.dir, pattern = "_2.fq.gz", full.names = TRUE)) # idem. por√©m com os arquivos pair 2/reverse

names <- sapply(strsplit(basename(forwards), "_1", "_2"), `[`, 1) # Define os nomes das amostras na vari√°vel names
```

#### 2.3. Control de Qualidade

``` r
quality.forwards <- plotQualityProfile(forwards)
#> Warning: `guides(<scale> = FALSE)` is deprecated. Please use `guides(<scale> =
#> "none")` instead.
quality.forwards  # Qualidade dos pair 1/forward
```

<img src="imgs/unnamed-chunk-8-1.png" width="100%" /> Voc√™ pode gerar um
gr√°fico com todos os heat maps da qualidade das sequ√™ncias forward. Ou
s√≥ escolher algumas amostras para serem gr√°ficadas. Como no exemplo
embaixo, onde s√≥ foi gerado o gr√°fico com duas amostras das sequ√™ncias
reverse. Use as caixas para selecionar as amostras que quiser.

``` r
quality.reverses<- plotQualityProfile(reverses[1:2])
#> Warning: `guides(<scale> = FALSE)` is deprecated. Please use `guides(<scale> =
#> "none")` instead.
quality.reverses # Qualidade dos pair 2/reverse 
```

<img src="imgs/unnamed-chunk-9-1.png" width="100%" />

**Analisando o gr√°fico**: A escala de cinza √© um heat map da frequ√™ncia
de cada score de qualidade (*Phred Score*) para cada posi√ß√£o das bases.
A m√©dia desse valor est√° indicado com a linha verde, e os quartiles da
distribui√ß√£o da qualidade pelas linhas laranjas. O gr√°fico tamb√©m
apresenta a quantidade de sequ√™ncias (letras vermelhas)

No caso de ambas reads, √© necess√°rio fazer um corte no final das
sequ√™ncias onde a qualidade √© menor. Por tanto vamos a truncar as reads
forward a 200 bp (cortando as √∫ltimas 50 bases) e as reads reverse a 180
bp (cortando as √∫ltimas 70 bases). Como j√° foi descrito antes, a regi√£o
sequenciada nas amostras foi a V4 com um tamanho de 291 bp. Tendo
sequ√™ncias de 200 bp e 180 bp, ainda teremos uma zona de sobreposi√ß√£o de
189 bp. **Preste muita aten√ß√£o** a isto se a regi√£o sequenciada de suas
amostras for maior, por exemplo V3-V4, que tem um tamanho de \~460 bp.
Precisa manter pelo menos 20 nucleotideos de sobreposi√ß√£o.

#### 2.4. Filtragem

Ap√≥s determinar quais ser√£o os pontos de corte, por observa√ß√£o dos
gr√°ficos de qualidade, ent√£o ser√° usada a fun√ß√£o `filterAndTrim()` para
filtrar e trimar as sequ√™ncias.

``` r
filter.forwards <- file.path(my.dir, "filtered", paste0(names, "_F_filter.fq.gz")) # cria um diret√≥rio chamado "filtered" e cola os nomes das amostras (names) com "_F_filter.fq.gz"
filter.reverses <- file.path(my.dir, "filtered", paste0(names, "_R_filter.fq.gz")) # cria um diret√≥rio chamado "filtered" e cola os nomes das amostras (names) com "_R_filter.fq.gz"

names(filter.forwards) <- names # assigna os nomes das amostras
names(filter.reverses) <- names # assigna os nomes das amostras
```

Ser√£o usado par√¢metros *default*, nos par√¢metros. Para saber que √© cada
par√¢metro, d√≠gite `?filterAndTrim()`.

``` r
filter.out <- filterAndTrim(forwards, filter.forwards, reverses, filter.reverses, truncLen = c(200,180), 
                            maxN = 0, maxEE = c(2,2),
                            truncQ = 2, rm.phix = TRUE,
                            compress = TRUE,
                            multithread = TRUE)

filter.out
#>                  reads.in reads.out
#> sample10_1.fq.gz   149410    123234
#> sample12_1.fq.gz   136624    113389
#> sample2_1.fq.gz    148873    122431
#> sample4_1.fq.gz    140549    115579
#> sample6_1.fq.gz    122512    100721
#> sample7_1.fq.gz    140199    116075
```

Perceba que na fun√ß√£o, devem ser chamadas as sequ√™ncias forward, e as
reverse, assim como as vari√°veis assignadas para as reads filtradas.

Digitando o nome da vari√°vel criada para o processo de filtragem
`filter.out`, voc√™ vai obter informa√ß√£o sobre as reads que entraram
antes do processo e as que sairam despois da filtragem.

Se quiser conferir a qualidade depois da filtragem:

``` r
quality.forwards.filter <- plotQualityProfile(filter.forwards)
#> Warning: `guides(<scale> = FALSE)` is deprecated. Please use `guides(<scale> =
#> "none")` instead.
quality.forwards.filter
```

<img src="imgs/unnamed-chunk-12-1.png" width="100%" />

``` r
quality.reverses.filt <- plotQualityProfile(filter.reverses)
#> Warning: `guides(<scale> = FALSE)` is deprecated. Please use `guides(<scale> =
#> "none")` instead.
quality.reverses.filt
```

<img src="imgs/unnamed-chunk-12-2.png" width="100%" />

#### 2.5. Aprendendo da taxa de erros

O algor√≠tmo de **DADA2** faz uso de um modelo param√©trico de erros e
cada set de amostras tem taxas de erros diferentes. A fun√ß√£o
`learnErros()` aprende este modelo de erros dos dados, alternando a
estimativa das taxas de erro e a infer√™ncia da composi√ß√£o da amostra at√©
convergirem para uma solu√ß√£o conjuntamente consistente.

``` r
error.forwards <- learnErrors(filter.forwards, multithread = TRUE) # modelo de erros para reads forward
#> 115070800 total bases in 575354 reads from 5 samples will be used for learning the error rates.

error.reverses <- learnErrors(filter.reverses, multithread = TRUE) # modelo de erros para reads reverse
#> 103563720 total bases in 575354 reads from 5 samples will be used for learning the error rates.
```

``` r
plotErrors(error.forwards, nominalQ = TRUE) # plot modelo de erros
#> Warning: Transformation introduced infinite values in continuous y-axis
#> Transformation introduced infinite values in continuous y-axis
```

<img src="imgs/unnamed-chunk-14-1.png" width="100%" />

No plot, pode se observar as taxas de erro para cada transi√ß√£o de bases
(A‚Äì&gt;C, A‚Äì&gt;G,‚Ä¶). Os pontos representam os erros observados para
cada score de qualidade consenso. A linha preta mostra a taxa estimada
de erros ap√≥s aplicado o algor√≠tmo. A linha vermelha a taxa de erros
esperada. No exemplo a taxa de erros estimada (linha preta) tem um bom
ajuste √†s observadas (pontos) e as taxas de erro caem com o aumento da
qualidade como esperado.

#### 2.5. Infer√™ncia

A continua√ß√£o ser√° aplicado o algor√≠tmo de infer√™ncia, o qual ir√° a
detectar sequ√™ncias √∫nicas em cada amostra

``` r
dada.forwards <- dada(filter.forwards, err= error.forwards, multithread=TRUE)
#> Sample 1 - 123234 reads in 52575 unique sequences.
#> Sample 2 - 113389 reads in 52032 unique sequences.
#> Sample 3 - 122431 reads in 53634 unique sequences.
#> Sample 4 - 115579 reads in 51513 unique sequences.
#> Sample 5 - 100721 reads in 43892 unique sequences.
#> Sample 6 - 116075 reads in 52696 unique sequences.
```

``` r
dada.reverses <- dada(filter.reverses, err= error.reverses, multithread=TRUE)
#> Sample 1 - 123234 reads in 56033 unique sequences.
#> Sample 2 - 113389 reads in 52985 unique sequences.
#> Sample 3 - 122431 reads in 57275 unique sequences.
#> Sample 4 - 115579 reads in 51532 unique sequences.
#> Sample 5 - 100721 reads in 45117 unique sequences.
#> Sample 6 - 116075 reads in 51212 unique sequences.
```

Voc√™ pode explorar o resultado do algor√≠tmo de DADA2 em cada uma das
amostras:

``` r
dada.forwards[[4]]
#> dada-class: object describing DADA2 denoising results
#> 1355 sequence variants were inferred from 51513 input unique sequences.
#> Key parameters: OMEGA_A = 1e-40, OMEGA_C = 1e-40, BAND_SIZE = 16
```

Na amostra 4, ap√≥s o denoising, foram inferidas 1355 ASVs de 51513
sequ√™ncias √∫nicas.

#### 2.6. Merge

Agora √© momento de fazer o merge entre as reads forward e reverse para
obter as sequ√™ncias completas. Este processo √© feito por alinhamento das
reads forward com a sequ√™ncia complemento ou reverse para a forma√ß√£o das
sequ√™ncias ‚Äúcontig‚Äù. Por *default*, os contigs s√≥ ser√£o constru√≠dos se
entre as reads forward e reverse existe no m√≠nimo 12 bases de
sobreposi√ß√£o, e s√£o identicas na regi√£o de sobreposi√ß√£o.

``` r
mergers <- mergePairs(dada.forwards, filter.forwards, dada.reverses, filter.reverses,
                      verbose = TRUE)
#> 114732 paired-reads (in 1151 unique pairings) successfully merged out of 119729 (in 2863 pairings) input.
#> 104132 paired-reads (in 1130 unique pairings) successfully merged out of 109367 (in 3005 pairings) input.
#> 112368 paired-reads (in 1295 unique pairings) successfully merged out of 118138 (in 3169 pairings) input.
#> 106578 paired-reads (in 1158 unique pairings) successfully merged out of 111618 (in 2758 pairings) input.
#> 93417 paired-reads (in 942 unique pairings) successfully merged out of 97375 (in 2238 pairings) input.
#> 106470 paired-reads (in 1101 unique pairings) successfully merged out of 112105 (in 2880 pairings) input.

# Explore os contigs gerados na amostra 2
head(mergers[[2]])
#>                                                                                                                                                                                                                                                        sequence
#> 1 TACGGAGGATGCAAGCGTTATCCGGATTCATTGGGTTTAAAGGGTGCGCAGGCGGAATGATAAGTCAGTGGTGAAATCTCCCGGCTCAACCGGGAAACTGCCATTGATACTGTCATTCTTGAGTACAGTTGAAGTGGGCGGAATGTGTCATGTAGCGGTGAAATGCTTAGATATGACACAGAACACCGATAGCGAAGGCAGCTCACTAAGCTGTAACTGACGCTCATGCACGAAAGCGTGGGGATCAAACAGG
#> 2 TACGGAGGATGCGAGCGTTATCCGGATTCATTGGGTTTAAAGGGTGCGTAGGCGGACTATTAAGTCAGTGGTGAAATCCTGCAGCTTAACTGCAGAACTGCCATTGATACTGATAGCCTTGAGTTTGGTTAAGGTAGGCGGAATGTGTAATGTAGCGGTGAAATGCTTAGATATTACACAGAACACCAATTGCGTAGGCAGCTTACTGAGCCGACACTGACGCTGAGGCACGAAAGCGTGGGGATCGAACAGG
#> 3 TACGTAGGGGGCGAGCGTTGTCCGAATTCACTGGGCGTAAAGCGCGCGTAGGCGGGTTTTTAAGTTGTGGGTGAAATTCCGAGGCTCAACCTCGTAACTGCCTGCAAAACTGGGAGCCTTGAGGTATGGAGAGGGAAGTGGAATTCCTGGTGTAGCGGTGAAATGCGTAGATATCAGGAGGAACACCCGTGGCGAAGGCGGCTTCCTGGCCATATCCTGACGCTGAGGTGCGAAAGCTAGGGTAGCGAACGGG
#> 4 TACGGAGGATGCAAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGCAGGTTGTTTTATAAGTCAGTGGTGAAAGTCTGTCGCTTAACGATAGGATTGCCATTGATACTGTAGGACTTGAGTATGGATGAGGTAGGCGGAATGTGTAGTGTAGCGGTGAAATGCATAGATATTACACAGAACGCCGATTGCGAAGGCAGCTTACTAATCCATGACTGACGCTGAGGCACGAAAGCGTGGGGATCAAACAGG
#> 5 TACGGGGGGTGCAAGCGTTGTTCGGAATTATTGGGCGTAAAGAGCGTGTAGGCGGCTGAATAAGTCAGATGTGAAATCCCTGGGCTTAACCCAGGAAGTGCATTTGAAACTATTCAGCTTGAGTAGGGGAGAGGAAAGTGGAATTCCTGGTGTAGAGGTGAAATTCGTAGATATCAGGAGGAACACCGGTGGCGAAGGCGACTTTCTGGCCCTATACTGACGCTGAGACGCGAGAGCGTGGGTAGCAAACAGG
#> 6 TACGTAGGGTGCGAGCGTTAATCGGAATTACTGGGCGTAAAGCGTGCGCAGGCGGTTTTGTAAGACAGATGTGAAATCCCCGGGCTTAACCTGGGAACTGCGTTTGTGACTGCAAGGCTAGAGTACGGCAGAGGGGGGTGGAATTCCTGGTGTAGCAGTGAAATGCGTAGATATCAGGAGGAACACCGATGGCGAAGGCAGCCCCCTGGGCCTGTACTGACGCTCATGCACGAAAGCGTGGGGAGCAAACAGG
#>   abundance forward reverse nmatch nmismatch nindel prefer accept
#> 1      2782       1       2    127         0      0      1   TRUE
#> 2      2083       2       1    127         0      0      2   TRUE
#> 3      1849       3       4    127         0      0      1   TRUE
#> 4      1665       4       3    127         0      0      2   TRUE
#> 5      1574       5       5    127         0      0      2   TRUE
#> 6      1435       7       6    127         0      0      1   TRUE
```

O objeto `mergers` √© uma lista de `data.frames` de cada amostra. Cada
`data.frame` cont√©m os ‚Äúcontigs‚Äù `$sequence`, a abund√¢ncia `$abudance`,
os √≠ndices das reads `$forward` e `$reverse` que foram unidas. As
sequ√™ncias pareadas que n√£o tinham sobreposi√ß√£o exata foram removidas no
comando anterior.

**Nota:** Normalmente na maioria das sequ√™ncias √© feito o merge
tranquilamente. Se n√£o √© no caso de suas amostras, √© necess√°rio rever os
passos anteriores. Poss√≠velmente na fase de trimagem foi removida a √°rea
de sobreposi√ß√£o.

#### 2.7. Contruindo a tabela de sequ√™ncias

Com a fun√ß√£o `makeSequenceTable()` ser√° criada a tabela das sequ√™ncias.

``` r
sequence.table <- makeSequenceTable(mergers)
dim(sequence.table)
#> [1]    6 2622
```

A tabela de sequ√™ncias √© uma matriz que est√° organizada assim: as
colunas s√£o ASVs (2622), e as linhas s√£o as amostras (6), e os dados
correspondem a n√∫mero de vezes que foi encontrada cada uma das
sequ√™ncias em cada uma das amostras (frequ√™ncias).

A continua√ß√£o, d√™ uma olhada na distribui√ß√£o dos tamanhos da sequ√™ncias.

``` r
table(nchar(getSequences(sequence.table)))
#> 
#>  208  223  250  251  252  253  254  255  256  261  262  286  301 
#>    1    1    1    3  118 2362  122    6    2    1    1    1    3
```

#### 2.8. Remo√ß√£o de Chimeras

O algor√≠tmo `dada` √© capaz de corregir erros de substitui√ß√£o e indels,
por√©m as chimeras podem permanecer. No entanto, devido √† acur√°cia do
m√©todo de denoising faz que identificar chimeras seja relativamente
f√°cil.

``` r
sequence.table.nochim <- removeBimeraDenovo(sequence.table,method = "consensus", multithread=TRUE, verbose=TRUE)
#> Identified 65 bimeras out of 2622 input sequences.

dim(sequence.table.nochim)
#> [1]    6 2557
```

``` r
sum(sequence.table.nochim)/sum(sequence.table)
#> [1] 0.9954822
```

A frequ√™ncia de chimeras varia bastante de dataset para dataset, e
depende de fatores como procedimentos experimentais e a complexidade da
amostra. No dataset deste tutorial s√≥ 1% das sequ√™ncias ap√≥s o merge
eram chimeras.

**Nota:** A maioria das reads devem permancer ap√≥s a remo√ß√£o das
chimeras. Se no seu dataset, voc√™ tiver uma porcentagem alta de
chimeras, deve rever os primeiros passos. O mais prov√°vel seja que os
primers n√£o foram removidos.

#### 2.8. Sumarizando

A continu√ß√£o ser√° criada uma tabela para sumarizar o n√∫mero de reads em
cada etapa do processo:

``` r
library(dplyr)
getN <- function(x) sum(getUniques(x))
resumo <- cbind(filter.out, sapply(dada.forwards, getN), sapply(dada.reverses, getN),
               sapply(mergers, getN), rowSums(sequence.table.nochim))

colnames(resumo) <- c("input", "filtered", "denoisedF", "denoisedR", "merged",
                     "nonchim")

rownames(resumo) <- names

resumo %>% 
  as_tibble() %>% 
  mutate(Porcentage.Surviving = (nonchim *100)/input)
#> # A tibble: 6 √ó 7
#>    input filtered denoisedF denoisedR merged nonchim Porcentage.Surviving
#>    <dbl>    <dbl>     <dbl>     <dbl>  <dbl>   <dbl>                <dbl>
#> 1 149410   123234    121368    120883 114732  114343                 76.5
#> 2 136624   113389    111399    110637 104132  103670                 75.9
#> 3 148873   122431    119843    119740 112368  111778                 75.1
#> 4 140549   115579    113334    112992 106578  105932                 75.4
#> 5 122512   100721     98839     98501  93417   92972                 75.9
#> 6 140199   116075    113946    113495 106470  106121                 75.7
```

Ap√≥s todas as fases, ficaram \~75% das sequ√™ncias em todas as amostras,
o qual √© muito bom.

#### 2.9. Anota√ß√£o Taxon√¥mica

Nesta fase √© usada uma base de dados com sequ√™ncias com asigna√ß√£o
taxon√¥mica conhecida. Uma das bases de dados mais usadas para
classifi√ß√£o taxon√¥mica de organismos es
[SILVA](https://www.arb-silva.de/), a qual cont√©m sequ√™ncias das
subunidades pequenas (SSU - *Small SubUnits*) dos ribossomas. Outras
bases de dados usadas s√£o [RDP](https://rdp.cme.msu.edu/) e
[GreenGenes](https://greengenes.secondgenome.com/).

Antes de usar as bases de dados directamente descarregadas da fonte, e
necess√°rio fazer um treinamento para poder us√°-las. No entanto, os
desenvolvedores de **DADA2** mant√©m as bases de dados **j√° treinadas**
de RDP, GreenGenes e Silva em formato `.fasta`. Para taxonomia de
fungos, a base de dados [UNITE ITS](https://unite.ut.ee/) pode se usada
direto da fonte.

Para este tutorial, fa√ßa *download* de
[silva\_nr\_v138\_train\_set.fa.gz](https://doi.org/10.5281/zenodo.4587954)
e coloque ele no diret√≥rio de trabalaho.

``` r
taxa.assig <- assignTaxonomy(sequence.table.nochim, "docs/silva_nr99_v138.1_train_set.fa.gz",
                             multithread = TRUE)
```

``` r
taxonomy <- taxa.assig

rownames(taxonomy) <- NULL

head(taxonomy)
#>      Kingdom    Phylum             Class             Order               
#> [1,] "Bacteria" "Bacteroidota"     "Bacteroidia"     "Bacteroidales"     
#> [2,] "Bacteria" "Bacteroidota"     "Bacteroidia"     "Bacteroidales"     
#> [3,] "Bacteria" "Bacteroidota"     "Bacteroidia"     "Sphingobacteriales"
#> [4,] "Bacteria" "Desulfobacterota" "Syntrophia"      "Syntrophales"      
#> [5,] "Bacteria" "Acidobacteriota"  "Aminicenantia"   "Aminicenantales"   
#> [6,] "Archaea"  "Euryarchaeota"    "Methanobacteria" "Methanobacteriales"
#>      Family                    Genus             
#> [1,] "Bacteroidetes vadinHA17" NA                
#> [2,] "Prolixibacteraceae"      NA                
#> [3,] "Lentimicrobiaceae"       NA                
#> [4,] "Smithellaceae"           "Smithella"       
#> [5,] NA                        NA                
#> [6,] "Methanobacteriaceae"     "Methanobacterium"
```

#### 2.10. BONUS TRACK: √Årvore Filogen√©tica com Qiime2-MAFFT-FASTTREE

Fazer o processamento de sequ√™ncias do gene 16S rRNA no DADA2 usando o
R, tem v√°rias vantagens, principalmente na performance do algor√≠tmo, com
o qual √© poss√≠vel encontrar mais ASVs. No entanto uma das principais
desvantagens de fazer o processamento no DADA2 √© que at√© hoje n√£o tem
sido disponibilizado uma ferramenta otimizada para fazer a √°rvore
filogen√©tica no R. Tem pacotes que fazem o alinhamento (`msa`) m√∫ltiplo
e outros que construem √°rvores (`phangorn`), mas n√£o foram criados para
alto n√∫mero de esp√©cies, como √© o caso de datasets de NGS. Por√©m, com
algumas formata√ß√µes e alguns comandos no R e Linux e uma integra√ß√£o com
Qiime2, √© poss√≠vel construir a t√£o desejada √°rvore filogen√©tica.

**1. Salvando a tabela de sequ√™ncias**

``` r
write.table(t(sequence.table.nochim), "seqtab-nochim.txt", sep="\t", row.names=TRUE, col.names=NA, quote=FALSE)
```

**2. Extra√≠ndo as sequ√™ncias representativas**

``` r
uniquesToFasta(sequence.table.nochim, fout='rep-seqs.fna', ids=colnames(sequence.table.nochim))
```

**3. Importando no Qiime2**

O seguinte comando √© no qiime2 no Linux (Se precisar deve fazer upload
dos arquivos `seqtab-nochim.txt` e `rep-seqs.fna` para o servidor onde
usa o qiime2)

    # Ativando o ambiente do qiime2
    conda activate qiime2-2021.4

    # Importando
    qiime tools import \
      --input-path rep-seqs.fna \
      --type 'FeatureData[Sequence]' \
      --output-path rep-seqs.qza

**4. Transformando para formato `.biom`**

    ## Adicionando o t√≠tulo especial do .biom
    echo -n "#OTU Table" | cat - seqtab-nochim.txt > biom-table.txt

    ## Transformando a .biom
    biom convert -i biom-table.txt -o table.biom --table-type="OTU table" --to-hdf5

**5. Importanto a tabela .biom como .qza**+

    qiime tools import \
      --input-path table.biom \
      --type 'FeatureTable[Frequency]' \
      --input-format BIOMV210Format \
      --output-path table.qza

Ao final destes 5 passos voc√™ ter√° o principais inputs para a constru√ß√£o
da √°rvore, as sequ√™ncias representativas `rep-seq.qza` e a tabela de
frequ√™ncias `table.qza`. Agora vai na se√ß√£o [**8. √Årvore
Filogen√©tica**](https://github.com/khidalgo85/metataxonomics#8-%C3%A1rvore-filogen%C3%AAtica)

Ao finalizar todos os processos voc√™ ter√° dois objetos principais: i)
tabela de frequ√™ncias (`sequence.table.nochim`) e ii) taxonomia
(`taxa.assig`), e a √°rvore (`tree.nwk`), os quais ser√£o usados nas
an√°lises *downstream.*

------------------------------------------------------------------------

# III An√°lises DownStream

Neste tutorial abordaremos algumas an√°lises DownStream que podem ser
feitas para este tipo de dados, especificamente usando a linguagem R. No
entanto antes existem outras ferramentas nas quais tamb√©m √© poss√≠vel
fazer an√°lises deste tipo. Aqui est√£o algumas delas:

-   [Raw Graphs](https://rawgraphs.io/): √â uma ferramenta on-line para
    generar gr√°ficos. Basta com organizar os dados e submeter na
    plataforma.

-   [Microbiome Analyst](https://www.microbiomeanalyst.ca/): √â outra
    ferramenta on-line espec√≠fica para an√°lises de microbiomas. Nesta
    ferramenta voc√™ deve subir os tr√™s arquivos finais e a tabela de
    metadados (`ASV_table.tsv`, `taxonomy.tsv`, `sample-metadata.txt` e
    `tree.nwk`)

-   [STAMP](https://github.com/LangilleLab/microbiome_helper/wiki/STAMP-preparation):
    Este programa permite fazer an√°lises estat√≠sticas e gerar gr√°ficos.

# Em constru√ß√£o
